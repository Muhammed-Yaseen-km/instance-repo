# ===========================================
# Inference Engine Configuration
# Copy to .env and modify as needed
# ===========================================

# === Celery / Redis ===
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# === Ollama ===
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=300

# === OpenRouter Fallback (optional) ===
OPENROUTER_API_KEY=
OPENROUTER_MODEL=anthropic/claude-3-5-sonnet

# === Authentication ===
API_KEY=                    # Leave empty to disable auth
RATE_LIMIT=60               # Requests per minute per IP (0 to disable)

# === Models ===
GENERAL_MODEL=qwen2.5:32b
JSON_MODEL=deepseek-coder-v2:16b
VISION_MODEL=qwen2.5vl:7b

# === CORS ===
CORS_ORIGINS=*              # Comma-separated origins, or * for all
                            # Note: credentials disabled with wildcard

# === File Uploads ===
UPLOAD_DIR=./data/uploads
MAX_UPLOAD_SIZE=10485760    # 10MB in bytes

# === Logging ===
LOG_LEVEL=INFO              # DEBUG, INFO, WARNING, ERROR
